{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "if os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n",
    "    endpoint_52f0a29528434bfb8e175ba5e12eec6f = 'https://s3-api.us-geo.objectstorage.softlayer.net'\n",
    "else:\n",
    "    endpoint_52f0a29528434bfb8e175ba5e12eec6f = 'https://s3-api.us-geo.objectstorage.service.networklayer.com'\n",
    "\n",
    "client_52f0a29528434bfb8e175ba5e12eec6f = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='UFGF7AYrp-80lX16kpyjAKmcJumsVTHh0jXTR8IFx4SL',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=endpoint_52f0a29528434bfb8e175ba5e12eec6f)\n",
    "\n",
    "body = client_52f0a29528434bfb8e175ba5e12eec6f.get_object(Bucket='iristensorflowv2-donotdelete-pr-p6snslldrbdnal',Key='iris.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_1 = pd.read_csv(body)\n",
    "df_data_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1cb58fd1d54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#품종 column을 one-hot-encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miris_data_one_hot_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0miris_data_one_hot_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#품종 column을 one-hot-encode\n",
    "iris_data_one_hot_encoded = pd.get_dummies(df_data_1)\n",
    "iris_data_one_hot_encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = {'Iris-setosa','Iris-versicolor','Iris-virginica'}\n",
    "feature_names = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']\n",
    "labels=df_data_1.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data sets\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = df_data_1[labels== target_name]\n",
    "    plt.plot(X_plot.iloc[:, 1], X_plot.iloc[:, 2], linestyle='none', marker='o', label=target_name)\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.axis('equal')\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = df_data_1[labels== target_name]\n",
    "    plt.plot(X_plot.iloc[:, 3], X_plot.iloc[:, 4], linestyle='none', marker='o', label=target_name)\n",
    "plt.xlabel(feature_names[2])\n",
    "plt.ylabel(feature_names[3])\n",
    "plt.axis('equal')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 데이터를 80%은 트레이닝 20% 테스트로 쪼갬\n",
    "iris_train_data = iris_data_one_hot_encoded.sample(frac=0.8, random_state=200)\n",
    "iris_test_data = iris_data_one_hot_encoded.drop(iris_train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input은 꽃잎의 너비와길이, 꽃받침의 너비와길이\n",
    "#output은 세개중 하나로\n",
    "iris_train_input_data = iris_train_data.filter(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])\n",
    "iris_train_label_data = iris_train_data.filter(['Species_Iris-setosa', 'Species_Iris-versicolor', 'Species_Iris-virginica'])\n",
    "iris_test_input_data = iris_test_data.filter(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])\n",
    "iris_test_label_data = iris_test_data.filter(['Species_Iris-setosa', 'Species_Iris-versicolor', 'Species_Iris-virginica'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x는 input값을 위한 placeholder\n",
    "#w는 가중치\n",
    "#b는 편차\n",
    "#y는 트레이닝해서 나온 결과(가설)\n",
    "#y_는 진짜 결과값\n",
    "x = tf.placeholder(tf.float32,[None, 4])\n",
    "W = tf.Variable(tf.zeros([4, 3]))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_entropy를 cost함수로\n",
    "cross_entropy  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=tf.matmul(x,W)+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost를 최소화\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#30,000번 학습\n",
    "#tf.global_variables_initializer().run()\n",
    "epoch_history = []\n",
    "loss_history = []\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for _ in range(30000):\n",
    "    #Usually send batches to the training step. But since the dataset is small sending all\n",
    "    l,a=sess.run([cross_entropy,train_step], feed_dict={x: iris_train_input_data, y_: iris_train_label_data})\n",
    "    epoch_history.append(_)\n",
    "    loss_history.append(l)\n",
    "\n",
    "print(\"trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossentropy vs. epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw Cross Entropy Graph\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('crossentropy')\n",
    "\n",
    "\n",
    "# Show the cross_entropy\n",
    "plt.plot(epoch_history, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "#정확도\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy : ', sess.run(accuracy, feed_dict={x: iris_test_input_data, y_: iris_test_label_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#추론\n",
    "predict_x = np.array([[6.9,3.1,5.4,2.1]])\n",
    "prediction=tf.argmax(y,1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={x: predict_x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x = np.array([[5.1,3.3,1.7,0.5]])\n",
    "prediction=tf.argmax(y,1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={x: predict_x}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# quality of the neural net using ROC curve and AUC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "#test인풋의 예측값\n",
    "test_prob=sess.run(tf.nn.softmax(logits=tf.matmul(x,W)+b), feed_dict={x: iris_test_input_data})\n",
    "#print(test_prob.ravel())\n",
    "\n",
    "#test인풋의 label\n",
    "test_label=sess.run(tf.argmax(y_,1), feed_dict={y_: iris_test_label_data})\n",
    "#print(test_label)\n",
    "\n",
    "#test인풋의 binarized\n",
    "bi_test_label = label_binarize(test_label, classes=[0, 1, 2])\n",
    "#print(bi_test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the actual dependent variable classifications for param 1, \n",
    "# and the confidences of the true classification for param 2.\n",
    "#roc_curve는 multiclass&multi_Indicater의 입력이 되지 않으므로 ravel()을 통해 1차원배열로 펼침\n",
    "fpr,tpr,thr= roc_curve(bi_test_label.ravel(), test_prob.ravel())\n",
    "AUC = auc(fpr,tpr)\n",
    "plt.plot(fpr, tpr,label='%s(area = %0.2f)' %('Model',AUC))\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.xlabel('위양성률(Fall-Out)')\n",
    "#plt.ylabel('재현률(Recall)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('label : ',test_label)\n",
    "test_pred=sess.run(tf.argmax(y,1), feed_dict={x: iris_test_input_data})\n",
    "print('predict: ',test_pred)\n",
    "\n",
    "confM=confusion_matrix(test_label,test_pred)\n",
    "print(confM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
